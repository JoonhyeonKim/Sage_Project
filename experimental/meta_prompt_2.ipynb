{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b0b89f",
   "metadata": {},
   "source": [
    "# Meta-Prompt\n",
    "\n",
    "This is a LangChain implementation of [Meta-Prompt](https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving), by [Noah Goodman](https://cocolab.stanford.edu/ndg), for building self-improving agents.\n",
    "\n",
    "The key idea behind Meta-Prompt is to prompt the agent to reflect on its own performance and modify its own instructions.\n",
    "\n",
    "![figure](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F468217b9-96d9-47c0-a08b-dbf6b21b9f49_492x384.png)\n",
    "\n",
    "Here is a description from the [original blog post](https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving):\n",
    "\n",
    "\n",
    "The agent is a simple loop that starts with no instructions and follows these steps:\n",
    "\n",
    "Engage in conversation with a user, who may provide requests, instructions, or feedback.\n",
    "\n",
    "At the end of the episode, generate self-criticism and a new instruction using the meta-prompt\n",
    "```\n",
    "Assistant has just had the below interactions with a User. Assistant followed their \"system: Instructions\" closely. Your job is to critique the Assistant's performance and then revise the Instructions so that Assistant would quickly and correctly respond in the future.\n",
    " \n",
    "####\n",
    "{hist}\n",
    "####\n",
    " \n",
    "Please reflect on these interactions.\n",
    "\n",
    "You should first critique Assistant's performance. What could Assistant have done better? What should the Assistant remember about this user? Are there things this user always wants? Indicate this with \"Critique: ...\".\n",
    "\n",
    "You should next revise the Instructions so that Assistant would quickly and correctly respond in the future. Assistant's goal is to satisfy the user in as few interactions as possible. Assistant will only see the new Instructions, not the interaction history, so anything important must be summarized in the Instructions. Don't forget any important details in the current Instructions! Indicate the new Instructions by \"Instructions: ...\".\n",
    "```\n",
    "\n",
    "Repeat.\n",
    "\n",
    "The only fixed instructions for this system (which I call Meta-prompt) is the meta-prompt that governs revision of the agentâ€™s instructions. The agent has no memory between episodes except for the instruction it modifies for itself each time. Despite its simplicity, this agent can learn over time and self-improve by incorporating useful details into its instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188fc2c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We define two chains. One serves as the `Assistant`, and the other is a \"meta-chain\" that critiques the `Assistant`'s performance and modifies the instructions to the `Assistant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62593c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6065c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chain(instructions, memory=None):\n",
    "    if memory is None:\n",
    "        memory = ConversationBufferWindowMemory()\n",
    "        memory.ai_prefix = \"Assistant\"\n",
    "\n",
    "    template = f\"\"\"\n",
    "    Instructions: {instructions}\n",
    "    {{{memory.memory_key}}}\n",
    "    Human: {{human_input}}\n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"history\", \"human_input\"], template=template\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=OpenAI(temperature=0),\n",
    "        prompt=prompt,\n",
    "        verbose=True,\n",
    "        memory=ConversationBufferWindowMemory(),\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "\n",
    "def initialize_meta_chain():\n",
    "    meta_template = \"\"\"\n",
    "    Assistant has just had the below interactions with a User. Assistant followed their \"Instructions\" closely. Your job is to critique the Assistant's performance and then revise the Instructions so that Assistant would quickly and correctly respond in the future.\n",
    "\n",
    "    ####\n",
    "\n",
    "    {chat_history}\n",
    "\n",
    "    ####\n",
    "\n",
    "    Please reflect on these interactions.\n",
    "\n",
    "    You should first critique Assistant's performance. What could Assistant have done better? What should the Assistant remember about this user? Are there things this user always wants? Indicate this with \"Critique: ...\".\n",
    "\n",
    "    You should next revise the Instructions so that Assistant would quickly and correctly respond in the future. Assistant's goal is to satisfy the user in as few interactions as possible. Assistant will only see the new Instructions, not the interaction history, so anything important must be summarized in the Instructions. Don't forget any important details in the current Instructions! Indicate the new Instructions by \"Instructions: ...\".\n",
    "    \"\"\"\n",
    "\n",
    "    meta_prompt = PromptTemplate(\n",
    "        input_variables=[\"chat_history\"], template=meta_template\n",
    "    )\n",
    "\n",
    "    meta_chain = LLMChain(\n",
    "        llm=OpenAI(temperature=0),\n",
    "        prompt=meta_prompt,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return meta_chain\n",
    "\n",
    "\n",
    "def get_chat_history(chain_memory):\n",
    "    memory_key = chain_memory.memory_key\n",
    "    chat_history = chain_memory.load_memory_variables(memory_key)[memory_key]\n",
    "    return chat_history\n",
    "\n",
    "\n",
    "def get_new_instructions(meta_output):\n",
    "    delimiter = \"Instructions: \"\n",
    "    new_instructions = meta_output[meta_output.find(delimiter) + len(delimiter) :]\n",
    "    return new_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f031f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(task, max_iters=3, max_meta_iters=5):\n",
    "    failed_phrase = \"task failed\"\n",
    "    success_phrase = \"task succeeded\"\n",
    "    key_phrases = [success_phrase, failed_phrase]\n",
    "\n",
    "    instructions = \"None\"\n",
    "    for i in range(max_meta_iters):\n",
    "        print(f\"[Episode {i+1}/{max_meta_iters}]\")\n",
    "        chain = initialize_chain(instructions, memory=None)\n",
    "        output = chain.predict(human_input=task)\n",
    "        for j in range(max_iters):\n",
    "            print(f\"(Step {j+1}/{max_iters})\")\n",
    "            print(f\"Assistant: {output}\")\n",
    "            print(\"Human: \")\n",
    "            human_input = input()\n",
    "            if any(phrase in human_input.lower() for phrase in key_phrases):\n",
    "                break\n",
    "            output = chain.predict(human_input=human_input)\n",
    "        if success_phrase in human_input.lower():\n",
    "            print(\"You succeeded! Thanks for playing!\")\n",
    "            return\n",
    "        meta_chain = initialize_meta_chain()\n",
    "        meta_output = meta_chain.predict(chat_history=get_chat_history(chain.memory))\n",
    "        print(f\"Feedback: {meta_output}\")\n",
    "        instructions = get_new_instructions(meta_output)\n",
    "        print(f\"New Instructions: {instructions}\")\n",
    "        print(\"\\n\" + \"#\" * 80 + \"\\n\")\n",
    "    print(\"You failed! Thanks for playing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dcbe6",
   "metadata": {},
   "source": [
    "## Specify a task and interact with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d72db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Provide a systematic argument for why we should always eat pasta with olives.\"\n",
    "main(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e1a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
