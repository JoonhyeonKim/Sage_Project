{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[snippet: Bismuth is a chemical element; it has symbol Bi and atomic number 83. It is a post-transition metal and one of the pnictogens, with chemical properties resembling its lighter group 15 siblings arsenic and antimony. Elemental bismuth occurs naturally, and its sulfide and oxide forms are important commercial ores., title: Bismuth - Wikipedia, link: https://en.wikipedia.org/wiki/Bismuth], [snippet: bismuth (Bi), the most metallic and the least abundant of the elements in the nitrogen group (Group 15 [Va] of the periodic table). Bismuth is hard, brittle, lustrous, and coarsely crystalline. It can be distinguished from all other metals by its colour—gray-white with a reddish tinge. History, title: Bismuth | Properties, Uses, Symbol, & Facts | Britannica, link: https://www.britannica.com/science/bismuth], [snippet: Optical Properties Occurrence In hydrothermal veins with ores of Co, Ni, Ag, and Sn; in pegmatites and topaz-bearing Sn-W quartz veins. Uses Area It is found free in nature and in minerals such as bismuthinite (Bi2S3) and bizmit (Bi2O3)., title: Bismuth | Physical - Optical Properties, Uses, Occurrence, link: https://geologyscience.com/minerals/bismuth/], [snippet: Bismuth is a famous shiny silvery-white metal with pink and blue iridescence. It is used in the production of cosmetics and pharmaceuticals. It has metaphysical properties that can promote physical healing and emotional balance. In particular, many practitioners claim that bismuth can help alleviate anxiety and stress., title: Bismuth Meanings, Healing Properties and Uses - The Fifth Element Life, link: https://thefifthelementlife.com/bismuth/]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke('what is a bismuth?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GutenbergLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/document_loaders/gutenberg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/modules/agents/quick_start\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import NotebookLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/document_loaders/jupyter_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make user to upload the ipynb and then analyse??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/document_loaders/microsoft_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/document_loaders/pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.text_splitter import Language\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/document_loaders/source_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import SeleniumURLLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/document_loaders/url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\\n\\n\\n\\n\\nQuickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\uf8ffü¶úÔ∏è\\uf8ffüîó LangChainDocsUse casesIntegrationsGuidesAPIMoreVersioningChangelogContributingTemplatesCookbooksTutorialsYouTube\\uf8ffü¶úÔ∏è\\uf8ffüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS DocsChatSearchGet startedIntroductionInstallationQuickstartSecurityLangChain Expression LanguageGet startedWhy use LCELInterfaceStreamingHow toCookbookLangChain Expression Language (LCEL)ModulesModel I/ORetrievalAgentsQuickstartConceptsAgent TypesHow-toAgentsToolsChainsMoreLangServeLangSmithLangGraphModulesAgentsQuickstartOn this pageQuickstartTo best understand the agent framework, let‚Äôs build an agent that has\\ntwo tools: one to look things up online, and one to look up specific\\ndata that we‚Äôve loaded into a index.This will assume knowledge of LLMs and\\nretrieval so if you haven‚Äôt already explored those\\nsections, it is recommended you do so.Setup: LangSmith‚ÄãBy definition, agents take a self-determined, input-dependent sequence\\nof steps before returning a user-facing output. This makes debugging\\nthese systems particularly tricky, and observability particularly\\nimportant. LangSmith is especially useful for such\\ncases.When building with LangChain, all steps will automatically be traced in\\nLangSmith. To set up LangSmith we just need set the following\\nenvironment variables:export LANGCHAIN_TRACING_V2=\"true\"export LANGCHAIN_API_KEY=\"<your-api-key>\"Define tools‚ÄãWe first need to create the tools we want to use. We will use two tools:\\nTavily (to search online) and\\nthen a retriever over a local index we will createTavily‚ÄãWe have a built-in tool in LangChain to easily use Tavily search engine\\nas tool. Note that this requires an API key - they have a free tier, but\\nif you don‚Äôt have one or don‚Äôt want to create one, you can always ignore\\nthis step.Once you create your API key, you will need to export that as:export TAVILY_API_KEY=\"...\"from langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults()search.invoke(\"what is the weather in SF\")[{\\'url\\': \\'https://www.metoffice.gov.uk/weather/forecast/9q8yym8kr\\',  \\'content\\': \\'Thu 11 Jan Thu 11 Jan Seven day forecast for San Francisco  San Francisco (United States of America) weather Find a forecast  Sat 6 Jan Sat 6 Jan Sun 7 Jan Sun 7 Jan Mon 8 Jan Mon 8 Jan Tue 9 Jan Tue 9 Jan Wed 10 Jan Wed 10 Jan Thu 11 Jan  Find a forecast Please choose your location from the nearest places to : Forecast days Today Today Sat 6 Jan Sat 6 JanSan Francisco 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV ... (11 January 2024) Time 00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 ... Oakland Int. 11.5 miles; San Francisco International 11.5 miles; Corte Madera 12.3 miles; Redwood City 23.4 miles;\\'}, {\\'url\\': \\'https://www.latimes.com/travel/story/2024-01-11/east-brother-light-station-lighthouse-california\\',  \\'content\\': \"May 18, 2023  Jan. 4, 2024 Subscribe for unlimited accessSite Map Follow Us MORE FROM THE L.A. TIMES  Jan. 8, 2024 Travel & Experiences This must be Elysian Valley (a.k.a. Frogtown) Jan. 5, 2024 Food  June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d\\'oeuvres are served in late afternoon ‚Äî outdoors if ...\"}]Retriever‚ÄãWe will also create a retriever over some data of our own. For a deeper\\nexplanation of each step here, see this\\nsectionfrom langchain.text_splitter import RecursiveCharacterTextSplitterfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_community.vectorstores import FAISSfrom langchain_openai import OpenAIEmbeddingsloader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")docs = loader.load()documents = RecursiveCharacterTextSplitter(    chunk_size=1000, chunk_overlap=200).split_documents(docs)vector = FAISS.from_documents(documents, OpenAIEmbeddings())retriever = vector.as_retriever()retriever.get_relevant_documents(\"how to upload a dataset\")[0]Document(page_content=\"dataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We\\'ve made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we\\'ve added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we‚Äôre being honest, most of\", metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\', \\'language\\': \\'en\\'})Now that we have populated our index that we will do doing retrieval\\nover, we can easily turn it into a tool (the format needed for an agent\\nto properly use it)from langchain.tools.retriever import create_retriever_toolretriever_tool = create_retriever_tool(    retriever,    \"langsmith_search\",    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",)Tools‚ÄãNow that we have created both, we can create a list of tools that we\\nwill use downstream.tools = [search, retriever_tool]Create the agent‚ÄãNow that we have defined the tools, we can create the agent. We will be\\nusing an OpenAI Functions agent - for more information on this type of\\nagent, as well as other options, see this guideFirst, we choose the LLM we want to be guiding the agent.from langchain_openai import ChatOpenAIllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)Next, we choose the prompt we want to use to guide the agent.If you want to see the contents of this prompt and have access to\\nLangSmith, you can go to:https://smith.langchain.com/hub/hwchase17/openai-functions-agentfrom langchain import hub# Get the prompt to use - you can modify this!prompt = hub.pull(\"hwchase17/openai-functions-agent\")prompt.messages[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\\'You are a helpful assistant\\')), MessagesPlaceholder(variable_name=\\'chat_history\\', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\\'input\\'], template=\\'{input}\\')), MessagesPlaceholder(variable_name=\\'agent_scratchpad\\')]Now, we can initalize the agent with the LLM, the prompt, and the tools.\\nThe agent is responsible for taking in input and deciding what actions\\nto take. Crucially, the Agent does not execute those actions - that is\\ndone by the AgentExecutor (next step). For more information about how to\\nthink about these components, see our conceptual guidefrom langchain.agents import create_openai_functions_agentagent = create_openai_functions_agent(llm, tools, prompt)Finally, we combine the agent (the brains) with the tools inside the\\nAgentExecutor (which will repeatedly call the agent and execute tools).\\nFor more information about how to think about these components, see our\\nconceptual guidefrom langchain.agents import AgentExecutoragent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)Run the agent‚ÄãWe can now run the agent on a few queries! Note that for now, these are\\nall stateless queries (it won‚Äôt remember previous interactions).agent_executor.invoke({\"input\": \"hi!\"})> Entering new AgentExecutor chain...Hello! How can I assist you today?> Finished chain.{\\'input\\': \\'hi!\\', \\'output\\': \\'Hello! How can I assist you today?\\'}agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})> Entering new AgentExecutor chain...Invoking: `langsmith_search` with `{\\'query\\': \\'LangSmith testing\\'}`[Document(page_content=\\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\', \\'language\\': \\'en\\'}), Document(page_content=\\'Skip to main content\\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\\\\u200bAt LangChain, all of us have LangSmith‚Äôs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript\\', metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\', \\'language\\': \\'en\\'}), Document(page_content=\\'You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We‚Äôve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing ‚Äî mirroring the\\', metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\', \\'language\\': \\'en\\'}), Document(page_content=\\'inputs, and see what happens. At some point though, our application is performing\\\\nwell and we want to be more rigorous about testing changes. We can use a dataset\\\\nthat we‚Äôve constructed along the way (see above). Alternatively, we could spend some\\\\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies\\', metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\', \\'language\\': \\'en\\'})]LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.For more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).> Finished chain.{\\'input\\': \\'how can langsmith help with testing?\\', \\'output\\': \\'LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:\\\\n\\\\n1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\\\\n\\\\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.\\\\n\\\\n3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.\\\\n\\\\n4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.\\\\n\\\\nFor more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).\\'}agent_executor.invoke({\"input\": \"whats the weather in sf?\"})> Entering new AgentExecutor chain...Invoking: `tavily_search_results_json` with `{\\'query\\': \\'weather in San Francisco\\'}`[{\\'url\\': \\'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/\\', \\'content\\': \\'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 11-01-2023 50¬∞F to 54¬∞F. 12-01-2023 50¬∞F to 59¬∞F. 13-01-2023 54¬∞F to ...\\'}, {\\'url\\': \\'https://www.latimes.com/travel/story/2024-01-11/east-brother-light-station-lighthouse-california\\', \\'content\\': \"May 18, 2023  Jan. 4, 2024 Subscribe for unlimited accessSite Map Follow Us MORE FROM THE L.A. TIMES  Jan. 8, 2024 Travel & Experiences This must be Elysian Valley (a.k.a. Frogtown) Jan. 5, 2024 Food  June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d\\'oeuvres are served in late afternoon ‚Äî outdoors if ...\"}]I\\'m sorry, I couldn\\'t find the current weather in San Francisco. However, you can check the weather in San Francisco by visiting a reliable weather website or using a weather app on your phone.> Finished chain.{\\'input\\': \\'whats the weather in sf?\\', \\'output\\': \"I\\'m sorry, I couldn\\'t find the current weather in San Francisco. However, you can check the weather in San Francisco by visiting a reliable weather website or using a weather app on your phone.\"}Adding in memory‚ÄãAs mentioned earlier, this agent is stateless. This means it does not\\nremember previous interactions. To give it memory we need to pass in\\nprevious chat_history. Note: it needs to be called chat_history\\nbecause of the prompt we are using. If we use a different prompt, we\\ncould change the variable name# Here we pass in an empty list of messages for chat_history because it is the first message in the chatagent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})> Entering new AgentExecutor chain...Hello Bob! How can I assist you today?> Finished chain.{\\'input\\': \\'hi! my name is bob\\', \\'chat_history\\': [], \\'output\\': \\'Hello Bob! How can I assist you today?\\'}from langchain_core.messages import AIMessage, HumanMessageagent_executor.invoke(    {        \"chat_history\": [            HumanMessage(content=\"hi! my name is bob\"),            AIMessage(content=\"Hello Bob! How can I assist you today?\"),        ],        \"input\": \"what\\'s my name?\",    })> Entering new AgentExecutor chain...Your name is Bob.> Finished chain.{\\'chat_history\\': [HumanMessage(content=\\'hi! my name is bob\\'),  AIMessage(content=\\'Hello Bob! How can I assist you today?\\')], \\'input\\': \"what\\'s my name?\", \\'output\\': \\'Your name is Bob.\\'}If we want to keep track of these messages automatically, we can wrap\\nthis in a RunnableWithMessageHistory. For more information on how to use\\nthis, see this guidefrom langchain_community.chat_message_histories import ChatMessageHistoryfrom langchain_core.runnables.history import RunnableWithMessageHistorymessage_history = ChatMessageHistory()agent_with_chat_history = RunnableWithMessageHistory(    agent_executor,    # This is needed because in most real world scenarios, a session id is needed    # It isn\\'t really used here because we are using a simple in memory ChatMessageHistory    lambda session_id: message_history,    input_messages_key=\"input\",    history_messages_key=\"chat_history\",)agent_with_chat_history.invoke(    {\"input\": \"hi! I\\'m bob\"},    # This is needed because in most real world scenarios, a session id is needed    # It isn\\'t really used here because we are using a simple in memory ChatMessageHistory    config={\"configurable\": {\"session_id\": \"<foo>\"}},)> Entering new AgentExecutor chain...Hello Bob! How can I assist you today?> Finished chain.{\\'input\\': \"hi! I\\'m bob\", \\'chat_history\\': [], \\'output\\': \\'Hello Bob! How can I assist you today?\\'}agent_with_chat_history.invoke(    {\"input\": \"what\\'s my name?\"},    # This is needed because in most real world scenarios, a session id is needed    # It isn\\'t really used here because we are using a simple in memory ChatMessageHistory    config={\"configurable\": {\"session_id\": \"<foo>\"}},)> Entering new AgentExecutor chain...Your name is Bob.> Finished chain.{\\'input\\': \"what\\'s my name?\", \\'chat_history\\': [HumanMessage(content=\"hi! I\\'m bob\"),  AIMessage(content=\\'Hello Bob! How can I assist you today?\\')], \\'output\\': \\'Your name is Bob.\\'}Conclusion‚ÄãThat‚Äôs a wrap! In this quick start we covered how to create a simple\\nagent. Agents are a complex topic, and there‚Äôs lot to learn! Head back\\nto the main agent page to find more resources on conceptual\\nguides, different types of agents, how to create custom tools, and more!PreviousAgentsNextConceptsSetup: LangSmithDefine toolsTavilyRetrieverToolsCreate the agentRun the agentAdding in memoryConclusionCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2024 LangChain, Inc.\\n\\n\\n\\n', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'})]\n"
     ]
    }
   ],
   "source": [
    "print(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='Skip to main content\\uf8ffü¶úÔ∏è\\uf8ffüîó LangChainDocsUse casesIntegrationsGuidesAPIMoreVersioningChangelogContributingTemplatesCookbooksTutorialsYouTube\\uf8ffü¶úÔ∏è\\uf8ffüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS DocsChatSearchGet startedIntroductionInstallationQuickstartSecurityLangChain Expression LanguageGet startedWhy use LCELInterfaceStreamingHow toCookbookLangChain Expression Language (LCEL)ModulesModel I/ORetrievalAgentsQuickstartConceptsAgent TypesHow-toAgentsToolsChainsMoreLangServeLangSmithLangGraphModulesAgentsQuickstartOn this pageQuickstartTo best understand the agent framework, let‚Äôs build an agent that has\\ntwo tools: one to look things up online, and one to look up specific\\ndata that we‚Äôve loaded into a index.This will assume knowledge of LLMs and\\nretrieval so if you haven‚Äôt already explored those\\nsections, it is recommended you do so.Setup: LangSmith‚ÄãBy definition, agents take a self-determined, input-dependent sequence', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='retrieval so if you haven‚Äôt already explored those\\nsections, it is recommended you do so.Setup: LangSmith‚ÄãBy definition, agents take a self-determined, input-dependent sequence\\nof steps before returning a user-facing output. This makes debugging\\nthese systems particularly tricky, and observability particularly\\nimportant. LangSmith is especially useful for such\\ncases.When building with LangChain, all steps will automatically be traced in\\nLangSmith. To set up LangSmith we just need set the following\\nenvironment variables:export LANGCHAIN_TRACING_V2=\"true\"export LANGCHAIN_API_KEY=\"<your-api-key>\"Define tools‚ÄãWe first need to create the tools we want to use. We will use two tools:\\nTavily (to search online) and\\nthen a retriever over a local index we will createTavily‚ÄãWe have a built-in tool in LangChain to easily use Tavily search engine\\nas tool. Note that this requires an API key - they have a free tier, but', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='as tool. Note that this requires an API key - they have a free tier, but\\nif you don‚Äôt have one or don‚Äôt want to create one, you can always ignore', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='this step.Once you create your API key, you will need to export that as:export TAVILY_API_KEY=\"...\"from langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults()search.invoke(\"what is the weather in SF\")[{\\'url\\': \\'https://www.metoffice.gov.uk/weather/forecast/9q8yym8kr\\',  \\'content\\': \\'Thu 11 Jan Thu 11 Jan Seven day forecast for San Francisco  San Francisco (United States of America) weather Find a forecast  Sat 6 Jan Sat 6 Jan Sun 7 Jan Sun 7 Jan Mon 8 Jan Mon 8 Jan Tue 9 Jan Tue 9 Jan Wed 10 Jan Wed 10 Jan Thu 11 Jan  Find a forecast Please choose your location from the nearest places to : Forecast days Today Today Sat 6 Jan Sat 6 JanSan Francisco 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV ... (11 January 2024) Time 00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 ... Oakland Int. 11.5 miles; San Francisco International 11.5 miles; Corte Madera 12.3 miles;', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='... (11 January 2024) Time 00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 ... Oakland Int. 11.5 miles; San Francisco International 11.5 miles; Corte Madera 12.3 miles; Redwood City 23.4 miles;\\'}, {\\'url\\': \\'https://www.latimes.com/travel/story/2024-01-11/east-brother-light-station-lighthouse-california\\',  \\'content\\': \"May 18, 2023  Jan. 4, 2024 Subscribe for unlimited accessSite Map Follow Us MORE FROM THE L.A. TIMES  Jan. 8, 2024 Travel & Experiences This must be Elysian Valley (a.k.a. Frogtown) Jan. 5, 2024 Food  June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d\\'oeuvres are served in late afternoon ‚Äî outdoors if ...\"}]Retriever‚ÄãWe will also create a retriever over some data of our own. For a deeper', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='explanation of each step here, see this', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='sectionfrom langchain.text_splitter import RecursiveCharacterTextSplitterfrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_community.vectorstores import FAISSfrom langchain_openai import OpenAIEmbeddingsloader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")docs = loader.load()documents = RecursiveCharacterTextSplitter(    chunk_size=1000, chunk_overlap=200).split_documents(docs)vector = FAISS.from_documents(documents, OpenAIEmbeddings())retriever = vector.as_retriever()retriever.get_relevant_documents(\"how to upload a dataset\")[0]Document(page_content=\"dataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We\\'ve made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we\\'ve added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we‚Äôre being honest, most of\", metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging.', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})Now that we have populated our index that we will do doing retrieval\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='over, we can easily turn it into a tool (the format needed for an agent\\nto properly use it)from langchain.tools.retriever import create_retriever_toolretriever_tool = create_retriever_tool(    retriever,    \"langsmith_search\",    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",)Tools‚ÄãNow that we have created both, we can create a list of tools that we\\nwill use downstream.tools = [search, retriever_tool]Create the agent‚ÄãNow that we have defined the tools, we can create the agent. We will be\\nusing an OpenAI Functions agent - for more information on this type of\\nagent, as well as other options, see this guideFirst, we choose the LLM we want to be guiding the agent.from langchain_openai import ChatOpenAIllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)Next, we choose the prompt we want to use to guide the agent.If you want to see the contents of this prompt and have access to', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='LangSmith, you can go to:https://smith.langchain.com/hub/hwchase17/openai-functions-agentfrom langchain import hub# Get the prompt to use - you can modify this!prompt = hub.pull(\"hwchase17/openai-functions-agent\")prompt.messages[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\\'You are a helpful assistant\\')), MessagesPlaceholder(variable_name=\\'chat_history\\', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\\'input\\'], template=\\'{input}\\')), MessagesPlaceholder(variable_name=\\'agent_scratchpad\\')]Now, we can initalize the agent with the LLM, the prompt, and the tools.\\nThe agent is responsible for taking in input and deciding what actions\\nto take. Crucially, the Agent does not execute those actions - that is\\ndone by the AgentExecutor (next step). For more information about how to', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='to take. Crucially, the Agent does not execute those actions - that is\\ndone by the AgentExecutor (next step). For more information about how to\\nthink about these components, see our conceptual guidefrom langchain.agents import create_openai_functions_agentagent = create_openai_functions_agent(llm, tools, prompt)Finally, we combine the agent (the brains) with the tools inside the\\nAgentExecutor (which will repeatedly call the agent and execute tools).\\nFor more information about how to think about these components, see our\\nconceptual guidefrom langchain.agents import AgentExecutoragent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)Run the agent‚ÄãWe can now run the agent on a few queries! Note that for now, these are', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='all stateless queries (it won‚Äôt remember previous interactions).agent_executor.invoke({\"input\": \"hi!\"})> Entering new AgentExecutor chain...Hello! How can I assist you today?> Finished chain.{\\'input\\': \\'hi!\\', \\'output\\': \\'Hello! How can I assist you today?\\'}agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})> Entering new AgentExecutor chain...Invoking: `langsmith_search` with `{\\'query\\': \\'LangSmith testing\\'}`[Document(page_content=\\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', metadata={\\'source\\': \\'https://docs.smith.langchain.com/overview\\', \\'title\\': \\'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\', \\'description\\': \\'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\', \\'language\\': \\'en\\'}), Document(page_content=\\'Skip to main', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='Skip to main content\\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\\\\u200bAt LangChain, all of us have LangSmith‚Äôs tracing running in the background by default. On the Python side, this\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"outline effective ways to use LangSmith and maximize its benefits.On by default\\\\u200bAt LangChain, all of us have LangSmith‚Äôs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"'language': 'en'}), Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We‚Äôve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing ‚Äî mirroring the', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='inputs, and see what happens. At some point though, our application is performing\\\\nwell and we want to be more rigorous about testing changes. We can use a dataset\\\\nthat we‚Äôve constructed along the way (see above). Alternatively, we could spend some\\\\ntime constructing a small dataset by hand. For\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"to be more rigorous about testing changes. We can use a dataset\\\\nthat we‚Äôve constructed along the way (see above). Alternatively, we could spend some\\\\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})]LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content=\"application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.For more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).> Finished chain.{'input': 'how can langsmith help with testing?', 'output': 'LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:\\\\n\\\\n1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\\\\n\\\\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets.\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='and troubleshoot specific issues as they arise.\\\\n\\\\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.\\\\n\\\\n3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.\\\\n\\\\n4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.\\\\n\\\\nFor more detailed information on how to use LangSmith for testing, you can refer to', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='construct small datasets by hand to test different scenarios and evaluate the performance of your application.\\\\n\\\\nFor more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).\\'}agent_executor.invoke({\"input\": \"whats the weather in sf?\"})> Entering new AgentExecutor chain...Invoking: `tavily_search_results_json` with `{\\'query\\': \\'weather in San Francisco\\'}`[{\\'url\\': \\'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/\\', \\'content\\': \\'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 11-01-2023 50¬∞F to 54¬∞F. 12-01-2023 50¬∞F to 59¬∞F. 13-01-2023 54¬∞F to ...\\'}, {\\'url\\': \\'https://www.latimes.com/travel/story/2024-01-11/east-brother-light-station-lighthouse-california\\', \\'content\\': \"May 18, 2023  Jan. 4, 2024 Subscribe for unlimited accessSite Map Follow Us MORE FROM THE L.A. TIMES  Jan. 8, 2024 Travel & Experiences This must be Elysian Valley (a.k.a. Frogtown) Jan. 5, 2024 Food  June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d\\'oeuvres are served in late afternoon ‚Äî', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='June 30, 2023The East Brother Light Station in the San Francisco Bay is not a destination for everyone. ... Jan. 11, 2024 3 AM PT ... Champagne and hors d\\'oeuvres are served in late afternoon ‚Äî outdoors if ...\"}]I\\'m sorry, I couldn\\'t find the current weather in San Francisco. However, you can check the weather in San Francisco by visiting a reliable weather website or using a weather app on your phone.> Finished chain.{\\'input\\': \\'whats the weather in sf?\\', \\'output\\': \"I\\'m sorry, I couldn\\'t find the current weather in San Francisco. However, you can check the weather in San Francisco by visiting a reliable weather website or using a weather app on your phone.\"}Adding in memory‚ÄãAs mentioned earlier, this agent is stateless. This means it does not', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='remember previous interactions. To give it memory we need to pass in\\nprevious chat_history. Note: it needs to be called chat_history\\nbecause of the prompt we are using. If we use a different prompt, we', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='could change the variable name# Here we pass in an empty list of messages for chat_history because it is the first message in the chatagent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})> Entering new AgentExecutor chain...Hello Bob! How can I assist you today?> Finished chain.{\\'input\\': \\'hi! my name is bob\\', \\'chat_history\\': [], \\'output\\': \\'Hello Bob! How can I assist you today?\\'}from langchain_core.messages import AIMessage, HumanMessageagent_executor.invoke(    {        \"chat_history\": [            HumanMessage(content=\"hi! my name is bob\"),            AIMessage(content=\"Hello Bob! How can I assist you today?\"),        ],        \"input\": \"what\\'s my name?\",    })> Entering new AgentExecutor chain...Your name is Bob.> Finished chain.{\\'chat_history\\': [HumanMessage(content=\\'hi! my name is bob\\'),  AIMessage(content=\\'Hello Bob! How can I assist you today?\\')], \\'input\\': \"what\\'s my name?\", \\'output\\': \\'Your name is Bob.\\'}If we want to keep track of these messages', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='my name is bob\\'),  AIMessage(content=\\'Hello Bob! How can I assist you today?\\')], \\'input\\': \"what\\'s my name?\", \\'output\\': \\'Your name is Bob.\\'}If we want to keep track of these messages automatically, we can wrap', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='this in a RunnableWithMessageHistory. For more information on how to use', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='this, see this guidefrom langchain_community.chat_message_histories import ChatMessageHistoryfrom langchain_core.runnables.history import RunnableWithMessageHistorymessage_history = ChatMessageHistory()agent_with_chat_history = RunnableWithMessageHistory(    agent_executor,    # This is needed because in most real world scenarios, a session id is needed    # It isn\\'t really used here because we are using a simple in memory ChatMessageHistory    lambda session_id: message_history,    input_messages_key=\"input\",    history_messages_key=\"chat_history\",)agent_with_chat_history.invoke(    {\"input\": \"hi! I\\'m bob\"},    # This is needed because in most real world scenarios, a session id is needed    # It isn\\'t really used here because we are using a simple in memory ChatMessageHistory    config={\"configurable\": {\"session_id\": \"<foo>\"}},)> Entering new AgentExecutor chain...Hello Bob! How can I assist you today?> Finished chain.{\\'input\\': \"hi! I\\'m bob\", \\'chat_history\\': [], \\'output\\': \\'Hello Bob!', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='{\"session_id\": \"<foo>\"}},)> Entering new AgentExecutor chain...Hello Bob! How can I assist you today?> Finished chain.{\\'input\\': \"hi! I\\'m bob\", \\'chat_history\\': [], \\'output\\': \\'Hello Bob! How can I assist you today?\\'}agent_with_chat_history.invoke(    {\"input\": \"what\\'s my name?\"},    # This is needed because in most real world scenarios, a session id is needed    # It isn\\'t really used here because we are using a simple in memory ChatMessageHistory    config={\"configurable\": {\"session_id\": \"<foo>\"}},)> Entering new AgentExecutor chain...Your name is Bob.> Finished chain.{\\'input\\': \"what\\'s my name?\", \\'chat_history\\': [HumanMessage(content=\"hi! I\\'m bob\"),  AIMessage(content=\\'Hello Bob! How can I assist you today?\\')], \\'output\\': \\'Your name is Bob.\\'}Conclusion‚ÄãThat‚Äôs a wrap! In this quick start we covered how to create a simple', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'}), Document(page_content='agent. Agents are a complex topic, and there‚Äôs lot to learn! Head back\\nto the main agent page to find more resources on conceptual\\nguides, different types of agents, how to create custom tools, and more!PreviousAgentsNextConceptsSetup: LangSmithDefine toolsTavilyRetrieverToolsCreate the agentRun the agentAdding in memoryConclusionCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2024 LangChain, Inc.', metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'})]\n"
     ]
    }
   ],
   "source": [
    "print(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.faiss.FAISS object at 0x7f5119761b10>\n"
     ]
    }
   ],
   "source": [
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'OpenAIEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f5119761b10>\n"
     ]
    }
   ],
   "source": [
    "print(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing ‚Äî mirroring the', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}), Document(page_content='inputs, and see what happens. At some point though, our application is performing\\\\nwell and we want to be more rigorous about testing changes. We can use a dataset\\\\nthat we‚Äôve constructed along the way (see above). Alternatively, we could spend some\\\\ntime constructing a small dataset by hand. For\", metadata={'source': 'https://python.langchain.com/docs/modules/agents/quick_start', 'title': 'Quickstart | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain', 'description': 'quickstart}', 'language': 'en'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"how to upload a dataset\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# llm = GoogleGenerativeAI(model=\"gemini-pro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mapplication is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.For more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).> Finished chain.{'input': 'how can langsmith help with testing?', 'output': 'LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:\\n\\n1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\\n\\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets.\n",
      "\n",
      "and troubleshoot specific issues as they arise.\\n\\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.\\n\\n3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.\\n\\n4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.\\n\\nFor more detailed information on how to use LangSmith for testing, you can refer to\n",
      "\n",
      "to be more rigorous about testing changes. We can use a dataset\\nthat we‚Äôve constructed along the way (see above). Alternatively, we could spend some\\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})]LangSmith can help with testing in several ways. Here are some ways LangSmith can assist with testing:1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as\n",
      "\n",
      "tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing in several ways:\n",
      "\n",
      "1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\n",
      "\n",
      "2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.\n",
      "\n",
      "3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.\n",
      "\n",
      "4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.\n",
      "\n",
      "For more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing in several ways:\\n\\n1. Tracing: LangSmith provides tracing capabilities that can be used to monitor and debug your application during testing. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\\n\\n2. Evaluation: LangSmith allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets. This can help you test and fine-tune your models for improved quality or reduced costs.\\n\\n3. Monitoring: Once your application is ready for production, LangSmith can be used to monitor your application. You can log feedback programmatically with runs, track performance over time, and pinpoint underperforming data points. This information can be used to improve your application and add to datasets for future testing.\\n\\n4. Rigorous Testing: When your application is performing well and you want to be more rigorous about testing changes, LangSmith can simplify the process. You can use existing datasets or construct small datasets by hand to test different scenarios and evaluate the performance of your application.\\n\\nFor more detailed information on how to use LangSmith for testing, you can refer to the [LangSmith Overview and User Guide](https://docs.smith.langchain.com/overview).'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[snippet: San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area., title: San Francisco, CA 10-Day Weather Forecast, link: https://www.wunderground.com/forecast/us/ca/san-francisco], [snippet: NWS Forecast Office San Francisco, CA. Weather.gov > San Francisco Bay Area, CA., title: San Francisco Bay Area, CA - National Weather Service, link: https://www.weather.gov/mtr/], [snippet: A storm system will produce a few weather hazards as it move across the southern U.S. this weekend. Heavy, accumulating snow is possible in the central and southern High Plains. Heavy rainfall will pose a flash flood threat from eastern Texas into the Tennessee Valley. Severe thunderstorms are possible across parts of the south into Monday., title: San Francisco Bay Area, CA - National Weather Service, link: https://www.weather.gov/mtr/ ], [snippet: Weather report for San Francisco. During the night and in the first hours of the day clear skies prevail, but after noon a few clouds are expected. It is a sunny day. Temperatures as high as 57 °F are foreseen. Overnight into Thursday a gentle breeze is expected (8 to 12 mph)., title: Weather San Francisco - meteoblue, link: https://www.meteoblue.com/en/weather/week/san-francisco_united-states_5391959]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco is currently sunny with temperatures as high as 57°F. Overnight, a gentle breeze is expected. You can find more detailed forecasts on [Weather San Francisco - meteoblue](https://www.meteoblue.com/en/weather/week/san-francisco_united-states_5391959).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'The weather in San Francisco is currently sunny with temperatures as high as 57°F. Overnight, a gentle breeze is expected. You can find more detailed forecasts on [Weather San Francisco - meteoblue](https://www.meteoblue.com/en/weather/week/san-francisco_united-states_5391959).'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[snippet: Get the latest weather information for San Francisco, CA, including temperature, precipitation, wind speed, humidity, pressure and more. See historical weather data, maps, radar, news and blogs for the San Francisco area., title: San Francisco, CA 10-Day Weather Forecast, link: https://www.wunderground.com/forecast/us/ca/san-francisco], [snippet: NWS Forecast Office San Francisco, CA. Weather.gov > San Francisco Bay Area, CA., title: San Francisco Bay Area, CA - National Weather Service, link: https://www.weather.gov/mtr/], [snippet: Get the current weather conditions and forecast for San Francisco, California, United States, with temperature, wind speed, precipitation, sea/surf forecast and more. See the icon, temperature felt, wind direction and speed, precipitation probability and hourly forecast for today and the next days., title: Weather San Francisco - meteoblue, link: https://www.meteoblue.com/en/weather/week/san-francisco_united-states_5391959], [snippet: Hourly Local Weather Forecast, weather conditions, precipitation, dew point, humidity, wind from Weather.com and The Weather Channel Hourly Weather Forecast for San Francisco, CA - The Weather ..., title: San Francisco, CA Weather, link: https://weather.com/weather/hourbyhour/l/d979bc5b5d21093ab384bfc39bc12d2126c86e159ce9baebc8a2931a59160a3f?traffic_source=footerNav_Hourly]\u001b[0m\u001b[32;1m\u001b[1;3mI found some resources where you can check the weather in San Francisco:\n",
      "1. [San Francisco, CA 10-Day Weather Forecast](https://www.wunderground.com/forecast/us/ca/san-francisco)\n",
      "2. [San Francisco Bay Area, CA - National Weather Service](https://www.weather.gov/mtr/)\n",
      "3. [Weather San Francisco - meteoblue](https://www.meteoblue.com/en/weather/week/san-francisco_united-states_5391959)\n",
      "4. [San Francisco, CA Weather - The Weather Channel](https://weather.com/weather/hourbyhour/l/d979bc5b5d21093ab384bfc39bc12d2126c86e159ce9baebc8a2931a59160a3f?traffic_source=footerNav_Hourly)\n",
      "\n",
      "You can visit these websites to get the current weather conditions and forecast for San Francisco.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I found some resources where you can check the weather in San Francisco:\\n1. [San Francisco, CA 10-Day Weather Forecast](https://www.wunderground.com/forecast/us/ca/san-francisco)\\n2. [San Francisco Bay Area, CA - National Weather Service](https://www.weather.gov/mtr/)\\n3. [Weather San Francisco - meteoblue](https://www.meteoblue.com/en/weather/week/san-francisco_united-states_5391959)\\n4. [San Francisco, CA Weather - The Weather Channel](https://weather.com/weather/hourbyhour/l/d979bc5b5d21093ab384bfc39bc12d2126c86e159ce9baebc8a2931a59160a3f?traffic_source=footerNav_Hourly)\\n\\nYou can visit these websites to get the current weather conditions and forecast for San Francisco.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob! How can I assist you today, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob! How can I assist you today, Bob?'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to keep track of these messages automatically, we can wrap this in a RunnableWithMessageHistory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_history.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_history.messages[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
